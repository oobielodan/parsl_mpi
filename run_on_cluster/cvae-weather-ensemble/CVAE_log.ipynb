{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6226ca5-0869-4973-8369-3469cbdff43c",
   "metadata": {
    "papermill": {
     "duration": 0.002598,
     "end_time": "2024-07-22T13:24:38.994861",
     "exception": false,
     "start_time": "2024-07-22T13:24:38.992263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **CVAE_training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094dca89-dffa-4a56-8263-371fb372a2cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:39.008804Z",
     "iopub.status.busy": "2024-07-22T13:24:39.008441Z",
     "iopub.status.idle": "2024-07-22T13:24:41.662895Z",
     "shell.execute_reply": "2024-07-22T13:24:41.662349Z"
    },
    "papermill": {
     "duration": 2.660987,
     "end_time": "2024-07-22T13:24:41.664087",
     "exception": false,
     "start_time": "2024-07-22T13:24:39.003100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:24:39.871109: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 13:24:39.871176: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 13:24:39.872741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 13:24:39.879336: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.16.2\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:24:41.608792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.656315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.658325: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import netCDF4\n",
    "import cartopy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8b533-cdaa-4efd-938b-ef1d5a84338e",
   "metadata": {
    "papermill": {
     "duration": 0.005739,
     "end_time": "2024-07-22T13:24:41.672560",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.666821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download and Convert Data\n",
    "On my [first Google hit for GEFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast), I clicked on [AWS Open Data Registry for GEFS](https://registry.opendata.aws/noaa-gefs-pds/) and selected [NOAA GEFS Re-forecast](https://registry.opendata.aws/noaa-gefs-reforecast/) which has no useage restrictions.  The [GEFS Re-forecast data documentation](https://noaa-gefs-retrospective.s3.amazonaws.com/Description_of_reforecast_data.pdf) is very clear and we're going to download two files, 57 MB each.  The date of the initialization of the re-forecast is in the file name in the format YYYYMMDDHH.  The c00, p01, p02, p03, p04 are the control and perturbation ensemble members (5 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b08e8b0-f9fa-40b9-852b-8650e681cff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:41.684894Z",
     "iopub.status.busy": "2024-07-22T13:24:41.684184Z",
     "iopub.status.idle": "2024-07-22T13:24:41.687336Z",
     "shell.execute_reply": "2024-07-22T13:24:41.686867Z"
    },
    "papermill": {
     "duration": 0.010184,
     "end_time": "2024-07-22T13:24:41.688483",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.678299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_prefix = \"./gefs_data\"\n",
    "data_dir = \"./gefs_data/converted/\"\n",
    "model_dir = './model_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff4403c-9c45-4129-902b-93ebfe9749e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:41.697302Z",
     "iopub.status.busy": "2024-07-22T13:24:41.697042Z",
     "iopub.status.idle": "2024-07-22T13:24:41.707954Z",
     "shell.execute_reply": "2024-07-22T13:24:41.707473Z"
    },
    "papermill": {
     "duration": 0.018426,
     "end_time": "2024-07-22T13:24:41.709041",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.690615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data definitions\n",
    "\n",
    "# data download\n",
    "def get_data(year, month, day, ensemble):\n",
    "    if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' not in os.listdir(data_prefix):\n",
    "        !wget -q -P {data_prefix} https://noaa-gefs-retrospective.s3.amazonaws.com/GEFSv12/reforecast/{year}/{year}{month}{day}00/{ensemble}/Days%3A1-10/pres_msl_{year}{month}{day}00_{ensemble}.grib2\n",
    "\n",
    "# data deletion\n",
    "def remove_data():\n",
    "    !find {data_prefix} -type f -delete\n",
    "\n",
    "# data loading\n",
    "def load_data(): \n",
    "    for f in os.listdir(data_dir):\n",
    "        if '.nc' in f:\n",
    "            os.system(f'ncks -v msl -d time,1,79,2 {data_dir}{f} -O {data_dir}subset_{f}')\n",
    "    \n",
    "    files = [f for f in os.listdir(data_dir) if ('subset' in f and 'tmp' not in f)]\n",
    "    \n",
    "    all_data = ((np.expand_dims(\n",
    "        np.concatenate(\n",
    "            [netCDF4.Dataset(data_dir + converted_file)['msl'][:] for converted_file in files]\n",
    "        ),\n",
    "        -1\n",
    "    ).astype(\"float32\") - 85000) / (110000 - 85000)).astype(\"float16\")\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ebb2a-bc7b-4f52-98d3-ec85c51c7a5f",
   "metadata": {
    "papermill": {
     "duration": 0.005436,
     "end_time": "2024-07-22T13:24:41.716586",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.711150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural Network Design\n",
    "\n",
    "We need to get to a small latent space. Conv2D networks are good because they help reduce the number of connections in a network in a meaningful way.  I'm using terms as defined in [this definition of conv2D](https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148).\n",
    "\n",
    "**Definitions:**\n",
    "K -> kernel size;\n",
    "P -> padding;\n",
    "S -> stride;\n",
    "D -> Dilation;\n",
    "G -> Groups\n",
    "\n",
    "**Filter options:**\n",
    "Longitude is easy because it is large and even, so as long as you have an even stride, you get integer results when dividing.\n",
    "e.g. lon 9: stride 4, lat 7: stride 5\n",
    "\n",
    "- Latitude - whole numbers occurr for P = 2 & K = 3 or K = 11.\n",
    "- 11 grid points * 0.25 deg * 100 km/deg = 275 km filter window (a good scale for weather)\n",
    "- 9 grid points * 0.25 deg * 100 km/deg = 225 km\n",
    "- Longitude - whole numbers occur for P = 0 & K = 11 (nice match with Latitude), P = 1 & K = 3 or 13, P = 2 & K = 5.\n",
    "\n",
    "For a 5 x 7 filter with 3 stride (no overlap) and no padding:\n",
    "- lat: (721 - 4) / 3 = 239 possible steps (good whole number!)\n",
    "- lon: (1440 - 4) / 3 = 478.6666 possible steps\n",
    "\n",
    "## Load and Preprocess Training Data:\n",
    "The standard way of manipulating arrays in Conv2D layers in TF is to use arrays in the shape:\n",
    "`batch_size,  height, width, channels = data.shape`\n",
    "In our case, the the `batch_size` is the number of image frames (i.e. separate samples or rows in a `.csv` file), the `height` and `width` define the size of the image frame in number of pixels, and the `channels` are the number of layers in the frames.  Typically, channels are color layers (e.g. RGB or CMYK) but in our case, we could use different metereological variables.  However, for this first experiment, **we only need one channel** because we're only going to use mean sea level pressure (msl).\n",
    "\n",
    "## Build the Encoder:\n",
    "GFS grids I have available here are at 0.25 degree resolution.  I'm doing this as a \"worst case\" scenario since there are also 0.5 and 1.0 degree grids with lower resolution but I can't find that data quickly and don't know what's available.\n",
    "\n",
    "These 0.25 degree grids are 721 x 1440.\n",
    "Each forecast file is 3 hourly for 10 days = 8 steps/forecast * 10 days = 80 \"frames\"\n",
    "This demo is only using two forecasts from the control ensemble\n",
    "(one launched Jan 01, 2019 and one launched Jan 02, 2019) -> this is only \n",
    "a small subset of the variability possible in the model.\n",
    "\n",
    "This particular data set spans 2000-2019 and there are 5 ensemble members.\n",
    "\n",
    "## Build the Decoder:\n",
    "With the 11 x 11 and 5 x 5 filters, non-overlapping stride, applied here, we have a final \"image\" size of 14 x 27 and 64 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0144303-f1c9-4220-8178-3988d707688c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:41.729974Z",
     "iopub.status.busy": "2024-07-22T13:24:41.729546Z",
     "iopub.status.idle": "2024-07-22T13:24:41.746443Z",
     "shell.execute_reply": "2024-07-22T13:24:41.745967Z"
    },
    "papermill": {
     "duration": 0.025407,
     "end_time": "2024-07-22T13:24:41.747543",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.722136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model defintions\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim):\n",
    "    encoder_inputs = keras.Input(shape=(721, 1440, 1))\n",
    "    \n",
    "    x = layers.Conv2D(32, 11, activation = \"relu\", strides = [9, 10], padding = \"valid\")(encoder_inputs)\n",
    "    x = layers.Conv2D(64, [5,9], activation = \"relu\", strides = [5, 9], padding = \"valid\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name = \"encoder\")\n",
    "    \n",
    "    print(encoder.summary())\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim):\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(15 * 15 * 64, activation=\"relu\")(latent_inputs)\n",
    "    x = layers.Reshape((15, 15, 64))(x)\n",
    "    # FIXME - there is something wrong here, but at least there is a pattern.\n",
    "    # Using output_padding as a fudge factor -> it may be that there is exactly\n",
    "    # one \"missing\" filter stamp/convolution because for both Conv2DTranspose\n",
    "    # operations, output_padding is set to maximum it could be in both dims\n",
    "    # (i.e. exactly one less than the stride of each filter).\n",
    "    x = layers.Conv2DTranspose(64, [5, 9], activation = \"relu\", strides = [5,9], padding = \"valid\", output_padding = [4, 8])(x)\n",
    "    x = layers.Conv2DTranspose(32, 11, activation = \"relu\", strides = [9,10], padding = \"valid\", output_padding = [8, 9])(x)\n",
    "    decoder_outputs = layers.Conv2DTranspose(1, 3, activation = \"sigmoid\", padding = \"same\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name = \"decoder\")\n",
    "    \n",
    "    print(decoder.summary())\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name = \"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name = \"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name = \"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            # FIXME: Normalize loss with the number of features (28 * 28)\n",
    "            n_features = 28 * 28\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis = (1, 2)\n",
    "                )\n",
    "            ) / n_features\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis = 1)) / n_features\n",
    "            total_loss = (reconstruction_loss + kl_loss)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    # Needed to validate (validation loss) and to evaluate\n",
    "    def test_step(self, data):\n",
    "        if type(data) == tuple:\n",
    "            data, _ = data\n",
    "            \n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        # FIXME: Normalize loss with the number of features (28 * 28)\n",
    "        n_features = 28 * 28\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction), axis = (1, 2)\n",
    "            )\n",
    "        ) / n_features\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis = 1)) / n_features\n",
    "        total_loss = (reconstruction_loss + kl_loss)\n",
    "        # grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        # self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61f638f-42a9-4d44-8f31-c6c42017a6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:41.756894Z",
     "iopub.status.busy": "2024-07-22T13:24:41.756548Z",
     "iopub.status.idle": "2024-07-22T13:24:41.794247Z",
     "shell.execute_reply": "2024-07-22T13:24:41.793782Z"
    },
    "papermill": {
     "duration": 0.045559,
     "end_time": "2024-07-22T13:24:41.795328",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.749769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training definitions\n",
    "\n",
    "def train_model(X_train, X_test, X_valid, date, vae):\n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True) # stops training early if the validation loss does not improve\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_dir, 'vae.weights.h5')): # if the model has already been trained at least once, load that model\n",
    "        vae.load_weights(os.path.join(model_dir, 'vae.weights.h5'))\n",
    "\n",
    "    history = vae.fit(\n",
    "        X_train, epochs = 50, batch_size = 40,\n",
    "        callbacks = [early_stopping_cb],\n",
    "        validation_data = (X_valid,)\n",
    "    )\n",
    "\n",
    "    vae.save_weights(os.path.join(model_dir, 'vae.weights.h5')) # save model weights after training\n",
    "    !cp model_dir/vae.weights.h5 model_dir/vae.weights_{date}.h5 # make a copy to dvc save\n",
    "    \n",
    "    hist_pd = pd.DataFrame(history.history)\n",
    "    hist_pd.to_csv(os.path.join(model_dir, f'history_{date}.csv'), index = False)\n",
    "\n",
    "    test_loss = vae.evaluate(X_test)\n",
    "    test_loss = dict(zip([\"loss\", \"reconstruction_loss\", \"kl_loss\"], test_loss))\n",
    "\n",
    "    print('Test loss:', test_loss)\n",
    "\n",
    "    with open(os.path.join(model_dir, f'test_loss_{date}.json'), 'w') as json_file:\n",
    "        json.dump(test_loss, json_file, indent = 4)\n",
    "        \n",
    "    !dvc add model_dir/history_{date}.csv\n",
    "    !git add .gitignore model_dir/history_{date}.csv.dvc\n",
    "    \n",
    "    !dvc add model_dir/vae.weights_{date}.h5\n",
    "    !git add .gitignore model_dir/vae.weights_{date}.h5.dvc\n",
    "    \n",
    "    !dvc push\n",
    "    !git commit -m f\"{date}\"\n",
    "    !git push\n",
    "    \n",
    "    !rm model_dir/vae.weights_{date}.h5 # delete copy\n",
    "    \n",
    "def run_train(num_files, date, vae):\n",
    "    slp = load_data() # load data\n",
    "    print(\"shape:\", np.shape(slp)) # verify data shape\n",
    "    \n",
    "    # split the data - y values are throw away\n",
    "    X_train, X_test, y_train, y_test = train_test_split(slp[0:(num_files * 40 - 1), :, :, :], np.arange(0, num_files * 40 - 1), test_size = 0.2, random_state = 1)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25, random_state = 1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    train_model(X_train, X_test, X_valid, date, vae)\n",
    "    remove_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defdd05-1774-4e56-bd64-2f760c004842",
   "metadata": {
    "papermill": {
     "duration": 0.005329,
     "end_time": "2024-07-22T13:24:41.803295",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.797966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dd6a16c-2ff9-42fe-bdcd-b8a970f88b9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:41.816024Z",
     "iopub.status.busy": "2024-07-22T13:24:41.815622Z",
     "iopub.status.idle": "2024-07-22T13:24:42.387113Z",
     "shell.execute_reply": "2024-07-22T13:24:42.386578Z"
    },
    "papermill": {
     "duration": 0.579215,
     "end_time": "2024-07-22T13:24:42.388285",
     "exception": false,
     "start_time": "2024-07-22T13:24:41.809070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:24:41.823997: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.826192: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.828082: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.961324: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.963212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.964786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-22 13:24:41.966304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20710 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">721</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1440</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">143</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,904</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">92,224</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14400</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">230,416</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m721\u001b[0m, \u001b[38;5;34m1440\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m, \u001b[38;5;34m143\u001b[0m,   │      \u001b[38;5;34m3,904\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m,    │     \u001b[38;5;34m92,224\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14400\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │    \u001b[38;5;34m230,416\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_mean (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m34\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sampling (\u001b[38;5;33mSampling\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">326,612</span> (1.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m326,612\u001b[0m (1.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">326,612</span> (1.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m326,612\u001b[0m (1.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Memory usage after building encoder: {'current': 1311232, 'peak': 3153408}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14400</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">143</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">184,384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">721</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">247,840</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">721</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1440</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14400\u001b[0m)          │        \u001b[38;5;34m43,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m, \u001b[38;5;34m143\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │       \u001b[38;5;34m184,384\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m721\u001b[0m, \u001b[38;5;34m1440\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │       \u001b[38;5;34m247,840\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m721\u001b[0m, \u001b[38;5;34m1440\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │           \u001b[38;5;34m289\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">475,713</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m475,713\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">475,713</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m475,713\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Memory usage after building decoder: {'current': 3216640, 'peak': 6049536}\n",
      "Memory usage after building VAE: {'current': 3219200, 'peak': 6049536}\n"
     ]
    }
   ],
   "source": [
    "# model build\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "# build encoder\n",
    "encoder = build_encoder(latent_dim)\n",
    "print(\"Memory usage after building encoder:\", tf.config.experimental.get_memory_info('GPU:0'))\n",
    "\n",
    "# build decoder\n",
    "decoder = build_decoder(latent_dim)\n",
    "print(\"Memory usage after building decoder:\", tf.config.experimental.get_memory_info('GPU:0'))\n",
    "\n",
    "# build VAE (variational autoencoder)\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer = 'rmsprop') \n",
    "print(\"Memory usage after building VAE:\", tf.config.experimental.get_memory_info('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c79096d-dee9-4ffc-9279-442e9232f20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:42.400557Z",
     "iopub.status.busy": "2024-07-22T13:24:42.400244Z",
     "iopub.status.idle": "2024-07-22T13:24:42.404257Z",
     "shell.execute_reply": "2024-07-22T13:24:42.403792Z"
    },
    "papermill": {
     "duration": 0.013522,
     "end_time": "2024-07-22T13:24:42.405377",
     "exception": false,
     "start_time": "2024-07-22T13:24:42.391855",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameter cell for pm \n",
    "year = \"2018\"\n",
    "day = \"01\"\n",
    "months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"] \n",
    "ensembles = [\"c00\"] #, \"p01\", \"p02\", \"p03\", \"p04\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf2e90f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:42.416547Z",
     "iopub.status.busy": "2024-07-22T13:24:42.416198Z",
     "iopub.status.idle": "2024-07-22T13:24:42.428678Z",
     "shell.execute_reply": "2024-07-22T13:24:42.428219Z"
    },
    "papermill": {
     "duration": 0.020658,
     "end_time": "2024-07-22T13:24:42.429814",
     "exception": false,
     "start_time": "2024-07-22T13:24:42.409156",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "year = \"2000\"\n",
    "day = \"25\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b952473d-6ec6-4581-8b49-d6d472b4e0cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:24:42.441377Z",
     "iopub.status.busy": "2024-07-22T13:24:42.440947Z"
    },
    "papermill": {
     "duration": 197.603631,
     "end_time": "2024-07-22T13:28:00.036762",
     "exception": false,
     "start_time": "2024-07-22T13:24:42.433131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ./gefs_data/pres_msl_2000012500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.46s 84MB]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ./gefs_data/pres_msl_2000022500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.47s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000032500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.48s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000042500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.47s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000052500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.46s 84MB]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ./gefs_data/pres_msl_2000062500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.47s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000072500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [1.58s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000082500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [2.35s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000092500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [2.74s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000102500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [2.91s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000112500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [3.06s 84MB]\r\n",
      "Working on ./gefs_data/pres_msl_2000122500_c00.grib2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdo    copy:   0%\b\b\b\b100%\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b\b \b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mcdo    copy: \u001b[0mProcessed 83059200 values from 1 variable over 80 timesteps [3.15s 84MB]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (480, 721, 1440, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lobielodan/pw/.miniconda3c/envs/cvae_env/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 20 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721654805.039496   81087 service.cc:145] XLA service 0x1505ac005520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721654805.040120   81087 service.cc:153]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-07-22 13:26:45.075609: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:26:45.267271: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:26:49.518059: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-22 13:26:49.518136: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-22 13:26:49.518159: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-22 13:26:49.518180: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-22 13:26:49.518201: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-22 13:26:49.518221: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-22 13:26:49.518241: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:26:52.073403: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[40,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:27:36.137331: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 45.063994231s\n",
      "Trying algorithm eng0{} for conv (f32[40,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 13:27:58.399466: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,721,1440]{3,2,1,0}, f32[40,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "num_files = 0\n",
    "\n",
    "# get wanted data -------------------------------------------------------------------------\n",
    "for month in months:\n",
    "    for ensemble in ensembles:\n",
    "        get_data(year, month, day, ensemble)\n",
    "\n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' in os.listdir(data_prefix):\n",
    "            num_files += 1\n",
    "# ------------------------------------------------------------------------------------------          \n",
    "            \n",
    "!csh batch_grib2nc.csh # convert files\n",
    "run_train(num_files, year + day, vae) # run training \n",
    "    \n",
    "print(\"Memory usage after training:\", tf.config.experimental.get_memory_info('GPU:0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 205.112626,
   "end_time": "2024-07-22T13:28:03.358597",
   "environment_variables": {},
   "exception": null,
   "input_path": "CVAE_training.ipynb",
   "output_path": "CVAE_log.ipynb",
   "parameters": {
    "day": "25",
    "year": "2000"
   },
   "start_time": "2024-07-22T13:24:38.245971",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}