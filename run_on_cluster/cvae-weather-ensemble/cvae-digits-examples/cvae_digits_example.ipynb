{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ae6efb-c776-4f57-853a-a7123c612918",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder example\n",
    "This notebook is a copy of [Francois Chollet's example](https://keras.io/examples/generative/vae/) but modified for online learning. In particular, some goals are:\n",
    "1. test computational performance scaling (CPUs, GPUs)\n",
    "2. test model performance while saving and fitting again (in particular, adding more data instead of having all the data available at once).\n",
    "3. integrations with DVC\n",
    "\n",
    "## Environment set up\n",
    "Based on the [Keras](https://keras.io/getting_started/) and [Tensorflow](https://www.tensorflow.org/install) instructions. We need Keras 3+ to be able to run this example. A simple `conda install tensorflow` will install TF 2.12 and Keras 2. I also tried using Python 3.11, but it appears that there may be some issues with underlying C libraries, so use Python 3.9:\n",
    "+ `conda create --name tf-cpu-py39 python=3.9`\n",
    "\n",
    "The following are required for connecting the kernel to a notebook:\n",
    "+ `conda install -q -y requests`\n",
    "+ `conda install -q -y ipykernel`\n",
    "+ `conda install -q -y -c anaconda jinja2`\n",
    "+ `conda install -q -y pandas matplotlib`\n",
    "\n",
    "Ensure pip is up to date, then install TF:\n",
    "+ `pip install --upgrade pip`\n",
    "+ `pip install tensorflow`\n",
    "+ `pip install tensorboard-plugin-profile`\n",
    "\n",
    "## Performance results\n",
    "\n",
    "4 CPUs -> 40 ms/step, ~22s per epoch\n",
    "\n",
    "8 CPUs -> 24 ms/step, ~13s per epoch\n",
    "\n",
    "T4 GPU -> ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc2c80-8eb8-46d0-888c-b70d26e71f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dea6e9-69e5-4cee-a546-a9db7792978b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = './model_d'\n",
    "\n",
    "os.makedirs(model_dir, exist_ok = True)\n",
    "os.makedirs(model_dir + '/model', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9583330-6383-440f-acc5-ce631cf9e27a",
   "metadata": {},
   "source": [
    "## Create sampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013491ac-f39f-44bb-9883-7a6cfcac1f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = ops.shape(z_mean)[0]\n",
    "        dim = ops.shape(z_mean)[1]\n",
    "        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4536fc-e359-49fb-bc52-54b9ff244d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70b33c-f2bd-41fb-83f4-90ac1c4afef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91004269-b7a7-4d19-8812-729cd8366b9e",
   "metadata": {},
   "source": [
    "## Build the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab93526-4805-4a62-95a8-3dbceb47950e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85405b6c-a092-49ad-9358-5e0c38622c59",
   "metadata": {},
   "source": [
    "## Define the VAE as a `Model` with a custom `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ef055-a698-4458-8b30-8671d3975195",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = ops.mean(\n",
    "                ops.sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
    "                    axis=(1, 2),\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - ops.square(z_mean) - ops.exp(z_log_var))\n",
    "            kl_loss = ops.mean(ops.sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f662b7-a8c8-4ae4-9f60-b6de69e0ddef",
   "metadata": {},
   "source": [
    "## Train the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc6419-1cbc-4261-ac12-92779e526d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True) # stops training early if the validation loss does not improve\n",
    "\n",
    "def train_model(count, vae, data):\n",
    "    if os.path.exists(os.path.join(model_dir, 'vae.weights.h5')): # if the model has already been trained at least once, load that model\n",
    "        vae.load_weights(os.path.join(model_dir, 'vae.weights.h5'))\n",
    "        \n",
    "    history = vae.fit(data, epochs=30, batch_size=128, callbacks = [early_stopping_cb])\n",
    "    vae.save_weights(os.path.join(model_dir, 'vae.weights.h5')) # save model weights after training\n",
    "    \n",
    "    hist_pd = pd.DataFrame(history.history)\n",
    "    hist_pd.to_csv(os.path.join(model_dir, f'history_{count}.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79963607-9800-4363-b0b0-280593559307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "# Insert new cells to create data subsets\n",
    "# Maybe plot data to check if it is a mix of different digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7c053-8c06-4378-8daf-65fe36b85fdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data subsets\n",
    "count = 0\n",
    "\n",
    "for arr in np.array_split(mnist_digits, 5):\n",
    "    count += 1\n",
    "    train_model(count, vae, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494fca6-d4b7-4ef3-91a5-4f1422526fd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display a grid of reconstructed digits in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d63bff-e2c6-40a1-a8f8-d375b008557e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample, verbose=0)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc89d55-5962-463f-ab7f-f0332e2e3430",
   "metadata": {},
   "source": [
    "## Display how the latent space clusters digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dabfbc-7024-4831-8432-6682c42dab7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data, verbose=0)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "plot_label_clusters(vae, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e7ebb-9f92-44e5-8e4c-dede651f0d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
