{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Demo using CVAE on CORE2 data**\n",
    "This is based on an example from Keras.io by fchollet.  Please see last cell for original code and links.\n",
    "\n",
    "# Conda env Setup\n",
    "The following is the list steps needed to be taken in order to set up a correct conda environment for running this notebook.\n",
    "\n",
    "**Create Environment:**\n",
    "```bash\n",
    "source ~/pw/.miniconda3c/etc/profile.d/conda.sh\n",
    "conda create --name NAME python=3.9\n",
    "conda activate NAME\n",
    "```\n",
    "\n",
    "**Install Pacakages:** \n",
    "\n",
    "The following packages need to be installed on top of a typical base Conda env. Install the packages in the following order so the environment solves correctly:\n",
    "```bash\n",
    "conda install -y -c conda-forge tensorflow\n",
    "conda install -y -c conda-forge netCDF4          # For reading nc files\n",
    "conda install -y -c conda-forge cartopy          # For making maps\n",
    "conda install -y -c conda-forge matplotlib\n",
    "conda install -y -c conda-forge pandas\n",
    "conda install -y -c conda-forge scikit-learn\n",
    "conda install -y -c conda-forge papermill\n",
    "conda install -y -c conda-forge cdo              # For converting grib to nc\n",
    "```\n",
    "**Connect Notebook to Environment:**\n",
    "```bash\n",
    "conda install -y ipykernel\n",
    "conda install -y requests\n",
    "conda install -y -c anaconda jinja2\n",
    "python -m ipykernel install --user --name=NAME --display-name \"Python (NAME)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:14:33.514858: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-11 17:14:33.514912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-11 17:14:33.516578: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-11 17:14:33.522875: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.16.2\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 17:14:35.345050: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:14:35.391862: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:14:35.395409: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import netCDF4\n",
    "import cartopy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘gefs_data’: File exists\n",
      "mkdir: cannot create directory ‘gefs_data/converted’: File exists\n",
      "mkdir: cannot create directory ‘model_dir’: File exists\n"
     ]
    }
   ],
   "source": [
    "# make needed directories\n",
    "!mkdir gefs_data\n",
    "!mkdir gefs_data/converted\n",
    "!mkdir model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Convert Data\n",
    "On my [first Google hit for GEFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast), I clicked on [AWS Open Data Registry for GEFS](https://registry.opendata.aws/noaa-gefs-pds/) and selected [NOAA GEFS Re-forecast](https://registry.opendata.aws/noaa-gefs-reforecast/) which has no useage restrictions.  The [GEFS Re-forecast data documentation](https://noaa-gefs-retrospective.s3.amazonaws.com/Description_of_reforecast_data.pdf) is very clear and we're going to download two files, 57 MB each.  The date of the initialization of the re-forecast is in the file name in the format YYYYMMDDHH.  The c00, p01, p02, p03, p04 are the control and perturbation ensemble members (5 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data download\n",
    "def get_data(year, month, day, ensembles):\n",
    "    num_files = 0\n",
    "    \n",
    "    for ensemble in ensembles:\n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' not in os.listdir(data_prefix):\n",
    "            !wget -q -P {data_prefix} https://noaa-gefs-retrospective.s3.amazonaws.com/GEFSv12/reforecast/{year}/{year}{month}{day}00/{ensemble}/Days%3A1-10/pres_msl_{year}{month}{day}00_{ensemble}.grib2\n",
    "        \n",
    "        if f'pres_msl_{year}{month}{day}00_{ensemble}.grib2' in os.listdir(data_prefix):\n",
    "            num_files += 1\n",
    "            \n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete all files\n",
    "def remove_data():\n",
    "    !find {data_prefix} -type f -delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for getting and converting files \n",
    "num_files = get_data(\"2018\", \"01\", \"01\", [\"c00\"])\n",
    "!csh batch_grib2nc.csh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for loading data\n",
    "dataset = netCDF4.Dataset(data_dir + \"pres_msl_2018010100_c00.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for simple data access\n",
    "print(dataset) # look at data structure\n",
    "print(dataset.variables.keys())\n",
    "\n",
    "for var in dataset.variables:\n",
    "    print(dataset.variables[var])\n",
    "    # print(dataset.variables[var][:]) # prints actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection = cartopy.crs.LambertConformal())\n",
    "\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.LAKES, alpha = 0.5)\n",
    "ax.add_feature(cartopy.feature.STATES, edgecolor='grey')\n",
    "ax.set_extent([-120, -73, 23, 50])\n",
    "\n",
    "plt.contour(\n",
    "    dataset.variables['lon'][:],     # longitudes\n",
    "    dataset.variables['lat'][:],     # latitudes\n",
    "    dataset.variables['msl'][0,:,:], # actual data\n",
    "    transform = cartopy.crs.PlateCarree()) #, levels=np.arange(30000,110000,20000))\n",
    "\n",
    "plt.title('GEFSv12 SLP 2019 01 10 0000 UTC Cycle')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for pm -> change the lists to fit your needs\n",
    "years = [\"2000\"]# , \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\"] # , \"2007\", \"2008\", \"2009\", \n",
    "         # \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "months = [\"01\"] # , \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"] \n",
    "days = [\"00\", \"10\", \"20\"] # forecasts are 10 days long, so (01, 10, 20) provides converage of whole year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdays\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m d\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "d = str(days.toi + 1)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lobielodan/pw/.miniconda3c/envs/cvae_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing:   8%|▊         | 1/13 [00:00<00:10,  1.14cell/s]2024-07-11 17:15:22.113103: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-11 17:15:22.113174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-11 17:15:22.114685: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-11 17:15:22.121063: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 17:15:23.831994: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:23.877551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:23.881149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Executing:  62%|██████▏   | 8/13 [00:03<00:01,  3.01cell/s]2024-07-11 17:15:24.032316: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:24.035891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:24.039218: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:24.362426: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:24.364209: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:24.365599: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-11 17:15:24.367054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20710 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "Executing:  92%|█████████▏| 12/13 [00:19<00:00,  3.27cell/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720718145.009940   44307 service.cc:145] XLA service 0x1479740047d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720718145.009989   44307 service.cc:153]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-07-11 17:15:45.045149: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-11 17:15:45.234400: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-11 17:15:49.889631: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:49.889705: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:49.889729: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:49.889750: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:49.889770: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:49.889790: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:49.889813: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-11 17:15:52.455433: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[40,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:16:36.519851: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 45.064477525s\n",
      "Trying algorithm eng0{} for conv (f32[40,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:16:58.375348: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,721,1440]{3,2,1,0}, f32[40,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:17:03.080450: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.705170926s\n",
      "Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,721,1440]{3,2,1,0}, f32[40,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "I0000 00:00:1720718230.283982   44307 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-07-11 17:17:14.869713: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[15,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:17:30.771179: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 16.901529082s\n",
      "Trying algorithm eng0{} for conv (f32[15,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:17:40.930094: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,32,721,1440]{3,2,1,0}, f32[15,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:17:41.585409: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.655383366s\n",
      "Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[15,32,721,1440]{3,2,1,0}, f32[15,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:17:51.618429: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-11 17:18:26.672668: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 36.054301958s\n",
      "Trying algorithm eng0{} for conv (f32[32,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "Executing: 100%|██████████| 13/13 [03:56<00:00, 18.19s/cell]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m12\u001b[39m):\n\u001b[1;32m      6\u001b[0m     pm\u001b[38;5;241m.\u001b[39mexecute_notebook(\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVAE_training.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVAE_log.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m         parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(year \u001b[38;5;241m=\u001b[39m y, month \u001b[38;5;241m=\u001b[39m m, days \u001b[38;5;241m=\u001b[39m d),\n\u001b[1;32m     10\u001b[0m         kernel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcvae_env\u001b[39m\u001b[38;5;124m'\u001b[39m   \n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 12\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mdays\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "d = days\n",
    "\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        for i in range(12):\n",
    "            pm.execute_notebook(\n",
    "                'CVAE_training.ipynb',\n",
    "                'CVAE_log.ipynb',\n",
    "                parameters = dict(year = y, month = m, days = d),\n",
    "                kernel_name = 'cvae_env'   \n",
    "            )\n",
    "            d = str(int(days) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try different filter sizes\n",
    "# Aim for large initial filter > 200km scale (about 10)\n",
    "# Aim for some, but minimal overlap in initial filter.\n",
    "\n",
    "# Aim for smallish second filter, but still try to reduce dimensionality\n",
    "# to make dense network tractable later. No overlap (but no good\n",
    "# reason why this is).\n",
    "\n",
    "# ----------------------Input: 721 x 1440--------------\n",
    "\n",
    "# For Lat = 721,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 9 -> H_out = 79.0\n",
    "\n",
    "# For Lon = 1440,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 10 -> H_out = 143.0\n",
    "\n",
    "# -----------------------Layer1: 79 x 143----------------\n",
    "\n",
    "# For Lat = 79,\n",
    "# K = 5 -> K_radius = 2.0 -> S = 5 -> H_out = 15.0\n",
    "\n",
    "# For Lon = 143,\n",
    "# K = 9 -> K_radius = 4.0 -> S = 9 -> H_out = 15.0\n",
    "\n",
    "'''\n",
    "H_in = 1440\n",
    "P = 0\n",
    "K_list = [3, 5, 7, 9, 11, 13, 15]                    # Kernel size\n",
    "S_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] # Stride\n",
    "\n",
    "for K in K_list:\n",
    "    for S in S_list:\n",
    "        K_radius = np.floor(np.divide(K, 2))   # Half width of number of points around the central point\n",
    "        K_diameter = K - 1                     # Number of points around the central point, ASSUMES K = ODD\n",
    "        # S = K                                # S = K is stride necessary to have non-overlapping filters\n",
    "        print('K = ' + str(K) + ' -> K_radius = ' + str(K_radius) + ' -> S = ' + str(S) + ' -> H_out = ' + str((H_in + (2 * P) - K_diameter) / S))\n",
    "    print('')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display a grid of sampled digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if latent_dim == 2:\n",
    "#     plot_latent_space(vae, path = os.path.join(model_dir, 'latent_space.png'))\n",
    "\n",
    "# # Generating new images\n",
    "# codings = tf.random.normal(shape = [12, latent_dim])\n",
    "# images = vae.decoder(codings).numpy()\n",
    "# plot_images(images, 3, 4, path = os.path.join(model_dir, 'generated.png'))\n",
    "\n",
    "# # Semantic interpolation\n",
    "# codings_grid = tf.reshape(codings, [1, 3, 4, latent_dim])\n",
    "# larger_grid = tf.image.resize(codings_grid, size = [5, 7])\n",
    "# interpolated_codings = tf.reshape(larger_grid, [-1, latent_dim])\n",
    "# images = vae.decoder(interpolated_codings).numpy()\n",
    "# plot_images(images, 5, 7, path = os.path.join(model_dir, 'interpolated.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display how the latent space clusters different digit classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_label_clusters(vae, data, labels):\n",
    "#     # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "# x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "# plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
