{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Demo using CVAE on CORE2 data**\n",
    "This is based on an example from Keras.io by fchollet.  Please see last cell for original code and links.\n",
    "\n",
    "# Conda env Setup\n",
    "The following is the list steps needed to be taken in order to set up a correct conda environment for running this notebook.\n",
    "\n",
    "**Create Environment:**\n",
    "```bash\n",
    "source ~/pw/.miniconda3c/etc/profile.d/conda.sh\n",
    "conda create --name <NAME> python=3.9\n",
    "conda activate <NAME>\n",
    "```\n",
    "\n",
    "**Install Pacakages:** \n",
    "\n",
    "The following packages need to be installed on top of a typical base Conda env. Install the packages in the following order so the environment solves correctly:\n",
    "```bash\n",
    "conda install -y -c conda-forge tensorflow\n",
    "conda install -y -c conda-forge netCDF4          # For reading nc files\n",
    "conda install -y -c conda-forge cartopy          # For making maps\n",
    "conda install -y -c conda-forge matplotlib\n",
    "conda install -y -c conda-forge pandas\n",
    "conda install -y -c conda-forge scikit-learn\n",
    "conda install -y -c conda-forge papermill\n",
    "conda install -y -c conda-forge dvc\n",
    "conda install -y -c conda-forge nco\n",
    "conda install -y -c conda-forge cdo              # For converting grib to nc\n",
    "```\n",
    "**Connect Notebook to Environment:**\n",
    "```bash\n",
    "conda install -y ipykernel\n",
    "conda install -y requests\n",
    "conda install -y -c anaconda jinja2\n",
    "python -m ipykernel install --user --name=<NAME> --display-name \"Python (<NAME>)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 20:19:40.901343: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 20:19:40.901395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 20:19:40.903066: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 20:19:40.909451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.16.2\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 20:19:42.721589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:42.771266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:42.774868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "import papermill as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import netCDF4\n",
    "import cartopy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make needed directories\n",
    "# use -p to make parent directories\n",
    "!mkdir -p gefs_data/converted\n",
    "!mkdir -p model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!dvc init --subdir\n",
    "!dvc remote add -d dvcstorage /aws-dvc-bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make DVC initialization commit\n",
    "!git add .\n",
    "!git commit -m \"loaded dependencies, mkdir -p, DVC init\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Convert Data\n",
    "On my [first Google hit for GEFS](https://www.ncei.noaa.gov/products/weather-climate-models/global-ensemble-forecast), I clicked on [AWS Open Data Registry for GEFS](https://registry.opendata.aws/noaa-gefs-pds/) and selected [NOAA GEFS Re-forecast](https://registry.opendata.aws/noaa-gefs-reforecast/) which has no useage restrictions.  The [GEFS Re-forecast data documentation](https://noaa-gefs-retrospective.s3.amazonaws.com/Description_of_reforecast_data.pdf) is very clear and we're going to download two files, 57 MB each.  The date of the initialization of the re-forecast is in the file name in the format YYYYMMDDHH.  The c00, p01, p02, p03, p04 are the control and perturbation ensemble members (5 total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.get_data import download_file\n",
    "from scripts.get_data import convert_file\n",
    "from scripts.get_data import remove_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pdir = \"./gefs_data\"\n",
    "data_dir = \"./gefs_data/converted/\"\n",
    "model_dir = './model_dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ex_year = \"2018\"\n",
    "ex_month = \"01\"\n",
    "ex_day = \"01\"\n",
    "ex_ensemble = \"c00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for getting and converting files \n",
    "download_file(ex_year, ex_month, ex_day, ex_ensemble, data_pdir)\n",
    "convert_file(ex_year, ex_month, ex_day, ex_ensemble, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for loading data\n",
    "dataset = netCDF4.Dataset(data_dir + f\"pres_msl_{ex_year}{ex_month}{ex_day}00_{ex_ensemble}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for simple data access\n",
    "print(dataset) # look at data structure\n",
    "print(dataset.variables.keys())\n",
    "\n",
    "for var in dataset.variables:\n",
    "    print(dataset.variables[var])\n",
    "    # print(dataset.variables[var][:]) # prints actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example for plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = plt.axes(projection = cartopy.crs.LambertConformal())\n",
    "\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.LAKES, alpha = 0.5)\n",
    "ax.add_feature(cartopy.feature.STATES, edgecolor='grey')\n",
    "ax.set_extent([-120, -73, 23, 50])\n",
    "\n",
    "plt.contour(\n",
    "    dataset.variables['lon'][:],     # longitudes\n",
    "    dataset.variables['lat'][:],     # latitudes\n",
    "    dataset.variables['msl'][0,:,:], # actual data\n",
    "    transform = cartopy.crs.PlateCarree()) #, levels=np.arange(30000,110000,20000))\n",
    "\n",
    "plt.title('GEFSv12 SLP 2019 01 10 0000 UTC Cycle')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Online Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up example data before executing online session\n",
    "remove_data(data_pdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for pm -> change the lists to fit your needs\n",
    "years = [\"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\"] # , \"2007\", \"2008\", \"2009\", \n",
    "         # \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "# months = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"] \n",
    "days = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \n",
    "        \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"] # forecasts are 10 days long, so (01, 10, 20) provides converage of whole year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lobielodan/pw/.miniconda3c/envs/cvae_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing:   8%|▊         | 1/13 [00:00<00:10,  1.10cell/s]2024-07-23 20:19:55.597300: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 20:19:55.597376: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 20:19:55.598931: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 20:19:55.605160: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 20:19:57.341784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.390045: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.393614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Executing:  62%|██████▏   | 8/13 [00:03<00:01,  2.93cell/s]2024-07-23 20:19:57.558831: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.562464: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.565788: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.727135: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.728924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.730542: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:19:57.732094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20710 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "Executing:  92%|█████████▏| 12/13 [00:19<00:00,  3.40cell/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721766110.515879  112615 service.cc:145] XLA service 0x1504f000c550 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721766110.515925  112615 service.cc:153]   StreamExecutor device (0): NVIDIA A10G, Compute Capability 8.6\n",
      "2024-07-23 20:21:50.551155: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 20:21:50.741363: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "2024-07-23 20:21:55.029005: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:55.029061: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:55.029086: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:55.029107: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:55.029122: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:55.029134: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:55.029146: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 20:21:57.587047: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[40,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:22:41.650018: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 45.063029839s\n",
      "Trying algorithm eng0{} for conv (f32[40,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:23:03.664262: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,721,1440]{3,2,1,0}, f32[40,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:23:08.368731: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.704550262s\n",
      "Trying algorithm eng0{} for conv (f32[64,32,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[40,32,721,1440]{3,2,1,0}, f32[40,64,79,143]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "I0000 00:00:1721766195.334430  112615 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-07-23 20:23:20.425805: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[7,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[7,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:23:27.314134: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 7.888384964s\n",
      "Trying algorithm eng0{} for conv (f32[7,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[7,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "I0000 00:00:1721766214.890244  112616 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion_2', 136 bytes spill stores, 136 bytes spill loads\n",
      "\n",
      "2024-07-23 20:23:41.258636: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[16,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:23:58.287342: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 18.028761027s\n",
      "Trying algorithm eng0{} for conv (f32[16,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:25:03.457866: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[32,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "2024-07-23 20:25:38.514255: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 36.056477657s\n",
      "Trying algorithm eng0{} for conv (f32[32,32,721,1440]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,79,143]{3,2,1,0}, f32[64,32,11,11]{3,2,1,0}), window={size=11x11 stride=9x10}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n",
      "Executing: 100%|██████████| 13/13 [06:02<00:00, 27.86s/cell]\n",
      "Executing:   8%|▊         | 1/13 [00:00<00:10,  1.10cell/s]2024-07-23 20:25:57.762284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 20:25:57.762360: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 20:25:57.763918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 20:25:57.770410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 20:25:59.486544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.532190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.534190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Executing:  62%|██████▏   | 8/13 [00:03<00:01,  2.98cell/s]2024-07-23 20:25:59.682589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.684747: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.686651: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.818578: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.820273: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.821872: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 20:25:59.823389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20710 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "Executing:  92%|█████████▏| 12/13 [00:17<00:00,  3.50cell/s]"
     ]
    }
   ],
   "source": [
    "for y in years:\n",
    "    for d in days:\n",
    "            pm.execute_notebook(\n",
    "                'CVAE_training.ipynb',\n",
    "                'CVAE_log.ipynb',\n",
    "                parameters = dict(year = y, day = d),\n",
    "                kernel_name = 'cvae_env'   \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try different filter sizes\n",
    "# Aim for large initial filter > 200km scale (about 10)\n",
    "# Aim for some, but minimal overlap in initial filter.\n",
    "\n",
    "# Aim for smallish second filter, but still try to reduce dimensionality\n",
    "# to make dense network tractable later. No overlap (but no good\n",
    "# reason why this is).\n",
    "\n",
    "# ----------------------Input: 721 x 1440--------------\n",
    "\n",
    "# For Lat = 721,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 9 -> H_out = 79.0\n",
    "\n",
    "# For Lon = 1440,\n",
    "# K = 11 -> K_radius = 5.0 -> S = 10 -> H_out = 143.0\n",
    "\n",
    "# -----------------------Layer1: 79 x 143----------------\n",
    "\n",
    "# For Lat = 79,\n",
    "# K = 5 -> K_radius = 2.0 -> S = 5 -> H_out = 15.0\n",
    "\n",
    "# For Lon = 143,\n",
    "# K = 9 -> K_radius = 4.0 -> S = 9 -> H_out = 15.0\n",
    "\n",
    "'''\n",
    "H_in = 1440\n",
    "P = 0\n",
    "K_list = [3, 5, 7, 9, 11, 13, 15]                    # Kernel size\n",
    "S_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] # Stride\n",
    "\n",
    "for K in K_list:\n",
    "    for S in S_list:\n",
    "        K_radius = np.floor(np.divide(K, 2))   # Half width of number of points around the central point\n",
    "        K_diameter = K - 1                     # Number of points around the central point, ASSUMES K = ODD\n",
    "        # S = K                                # S = K is stride necessary to have non-overlapping filters\n",
    "        print('K = ' + str(K) + ' -> K_radius = ' + str(K_radius) + ' -> S = ' + str(S) + ' -> H_out = ' + str((H_in + (2 * P) - K_diameter) / S))\n",
    "    print('')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display a grid of sampled digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if latent_dim == 2:\n",
    "#     plot_latent_space(vae, path = os.path.join(model_dir, 'latent_space.png'))\n",
    "\n",
    "# # Generating new images\n",
    "# codings = tf.random.normal(shape = [12, latent_dim])\n",
    "# images = vae.decoder(codings).numpy()\n",
    "# plot_images(images, 3, 4, path = os.path.join(model_dir, 'generated.png'))\n",
    "\n",
    "# # Semantic interpolation\n",
    "# codings_grid = tf.reshape(codings, [1, 3, 4, latent_dim])\n",
    "# larger_grid = tf.image.resize(codings_grid, size = [5, 7])\n",
    "# interpolated_codings = tf.reshape(larger_grid, [-1, latent_dim])\n",
    "# images = vae.decoder(interpolated_codings).numpy()\n",
    "# plot_images(images, 5, 7, path = os.path.join(model_dir, 'interpolated.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display how the latent space clusters different digit classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_label_clusters(vae, data, labels):\n",
    "#     # display a 2D plot of the digit classes in the latent space\n",
    "#     z_mean, _, _ = vae.encoder.predict(data)\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "#     plt.colorbar()\n",
    "#     plt.xlabel(\"z[0]\")\n",
    "#     plt.ylabel(\"z[1]\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# (x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "# x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "# plot_label_clusters(vae, x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cvae_env]",
   "language": "python",
   "name": "conda-env-cvae_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
